{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction of Imbalanced Bank Data set using Deep Learning and SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/ACHAL SHAH/Desktop/bankcustomerchurn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RowNumber','CustomerId','Surname','Geography'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2037"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Exited'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>644</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>155060.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29179.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>800</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167773.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7963 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "1             608  Female   41       1   83807.86              1          0   \n",
       "3             699  Female   39       1       0.00              2          0   \n",
       "4             850  Female   43       2  125510.82              1          1   \n",
       "6             822    Male   50       7       0.00              2          1   \n",
       "8             501    Male   44       4  142051.07              2          0   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9993          644    Male   28       7  155060.41              1          1   \n",
       "9994          800  Female   29       2       0.00              2          0   \n",
       "9995          771    Male   39       5       0.00              2          1   \n",
       "9996          516    Male   35      10   57369.61              1          1   \n",
       "9999          792  Female   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  \n",
       "1                  1        112542.58       0  \n",
       "3                  0         93826.63       0  \n",
       "4                  1         79084.10       0  \n",
       "6                  1         10062.80       0  \n",
       "8                  1         74940.50       0  \n",
       "...              ...              ...     ...  \n",
       "9993               0         29179.52       0  \n",
       "9994               0        167773.55       0  \n",
       "9995               0         96270.64       0  \n",
       "9996               1        101699.77       0  \n",
       "9999               0         38190.78       0  \n",
       "\n",
       "[7963 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Exited==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note the difference for people that Exited bank is 2037 vs 7963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13a7678ef88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tenure_churn_no = df[df.Exited==0].Tenure\n",
    "tenure_churn_yes = df[df.Exited==1].Tenure\n",
    "\n",
    "plt.xlabel(\"tenure\")\n",
    "plt.ylabel(\"Number Of Customers\")\n",
    "plt.title(\"Customer Churn Prediction Visualiztion\")\n",
    "\n",
    "plt.hist([tenure_churn_yes, tenure_churn_no], rwidth=0.95, color=['green','red'],label=['Exited=Yes','Exited=No'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert unique columns to 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_col_values(df):\n",
    "       for column in df:\n",
    "            if df[column].dtypes=='object':\n",
    "                print(f'{column}: {df[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender: ['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace({'Female':1,'Male':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Gender               int64\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = ['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore: [0.538 0.516 0.304 0.698 1.    0.59  0.944 0.052 0.302 0.668 0.356 0.294\n",
      " 0.252 0.398 0.57  0.532 0.606 0.474 0.752 0.764 0.572 0.32  0.638 0.992\n",
      " 0.454 0.812 0.442 0.448 0.122 0.482 0.366 0.406 0.34  0.744 0.25  0.28\n",
      " 0.908 0.464 0.244 0.23  0.412 0.968 0.62  0.852 0.958 0.574 0.4   0.696\n",
      " 0.47  0.876 0.61  0.502 0.612 0.75  0.322 0.528 0.784 0.674 0.41  0.506\n",
      " 0.802 0.462 0.77  0.622 0.65  0.776 0.926 0.614 0.508 0.338 0.628 0.656\n",
      " 0.814 0.132 0.63  0.854 0.386 0.312 0.286 0.604 0.8   0.758 0.592 0.594\n",
      " 0.916 0.348 0.838 0.76  0.33  0.846 0.928 0.72  0.126 0.546 0.64  0.544\n",
      " 0.87  0.51  0.258 0.67  0.376 0.424 0.742 0.556 0.636 0.956 0.648 0.55\n",
      " 0.164 0.84  0.816 0.89  0.672 0.878 0.478 0.222 0.468 0.458 0.626 0.664\n",
      " 0.886 0.682 0.27  0.6   0.808 0.37  0.732 0.378 0.712 0.472 0.562 0.734\n",
      " 0.9   0.666 0.708 0.53  0.634 0.268 0.26  0.456 0.324 0.512 0.494 0.856\n",
      " 0.328 0.35  0.73  0.46  0.914 0.342 0.818 0.332 0.722 0.536 0.586 0.642\n",
      " 0.678 0.54  0.652 0.444 0.69  0.484 0.434 0.688 0.394 0.488 0.646 0.52\n",
      " 0.834 0.826 0.724 0.706 0.624 0.618 0.346 0.844 0.39  0.568 0.778 0.842\n",
      " 0.662 0.388 0.692 0.832 0.754 0.686 0.414 0.362 0.296 0.602 0.882 0.766\n",
      " 0.922 0.714 0.728 0.864 0.85  0.898 0.504 0.788 0.476 0.794 0.466 0.554\n",
      " 0.762 0.558 0.176 0.584 0.912 0.248 0.418 0.158 0.66  0.798 0.768 0.588\n",
      " 0.552 0.598 0.91  0.736 0.98  0.56  0.608 0.824 0.436 0.526 0.344 0.774\n",
      " 0.596 0.186 0.58  0.38  0.22  0.486 0.902 0.522 0.904 0.79  0.266 0.68\n",
      " 0.284 0.718 0.71  0.42  0.804 0.702 0.374 0.274 0.492 0.704 0.272 0.748\n",
      " 0.396 0.228 0.88  0.368 0.796 0.288 0.48  0.236 0.318 0.936 0.932 0.372\n",
      " 0.806 0.848 0.542 0.438 0.616 0.896 0.582 0.384 0.684 0.578 0.83  0.44\n",
      " 0.576 0.498 0.564 0.858 0.354 0.428 0.966 0.308 0.984 0.316 0.134 0.496\n",
      " 0.782 0.514 0.822 0.996 0.392 0.178 0.81  0.82  0.352 0.726 0.7   0.632\n",
      " 0.432 0.29  0.676 0.524 0.254 0.154 0.978 0.938 0.74  0.218 0.306 0.548\n",
      " 0.358 0.426 0.264 0.892 0.19  0.792 0.872 0.408 0.644 0.874 0.298 0.988\n",
      " 0.2   0.93  0.976 0.906 0.772 0.566 0.5   0.658 0.334 0.884 0.786 0.276\n",
      " 0.142 0.982 0.716 0.314 0.31  0.212 0.17  0.422 0.336 0.43  0.756 0.868\n",
      " 0.404 0.518 0.828 0.694 0.746 0.402 0.188 0.738 0.292 0.382 0.96  0.924\n",
      " 0.654 0.14  0.49  0.534 0.918 0.3   0.952 0.168 0.326 0.256 0.894 0.026\n",
      " 0.098 0.226 0.86  0.204 0.45  0.974 0.888 0.948 0.156 0.946 0.862 0.998\n",
      " 0.278 0.162 0.214 0.836 0.962 0.018 0.94  0.446 0.452 0.416 0.934 0.198\n",
      " 0.18  0.13  0.942 0.36  0.    0.192 0.15  0.78  0.262 0.866 0.016 0.99\n",
      " 0.202 0.216 0.238 0.146 0.108 0.972 0.246 0.97  0.232 0.282 0.002 0.954\n",
      " 0.986 0.03  0.364 0.128 0.206 0.242 0.102 0.92  0.964 0.24  0.194 0.144\n",
      " 0.95  0.16  0.172 0.152 0.116 0.994 0.136 0.174 0.12  0.208 0.114 0.21\n",
      " 0.224 0.072 0.11  0.066 0.09  0.234 0.166 0.184 0.148 0.196 0.182 0.034\n",
      " 0.124 0.064 0.046 0.138]\n",
      "Gender: [1 0]\n",
      "Age: [0.32432432 0.31081081 0.28378378 0.33783784 0.35135135 0.43243243\n",
      " 0.14864865 0.12162162 0.17567568 0.08108108 0.21621622 0.09459459\n",
      " 0.22972973 0.36486486 0.54054054 0.18918919 0.27027027 0.37837838\n",
      " 0.24324324 0.2027027  0.2972973  0.44594595 0.58108108 0.41891892\n",
      " 0.25675676 0.01351351 0.64864865 0.51351351 0.10810811 0.04054054\n",
      " 0.5        0.77027027 0.05405405 0.16216216 0.13513514 0.63513514\n",
      " 0.40540541 0.45945946 0.52702703 0.74324324 0.39189189 0.48648649\n",
      " 0.72972973 0.02702703 0.66216216 0.82432432 0.59459459 0.47297297\n",
      " 0.83783784 0.55405405 0.67567568 0.06756757 0.56756757 0.7027027\n",
      " 0.60810811 0.62162162 0.         0.86486486 0.68918919 0.75675676\n",
      " 0.71621622 0.78378378 0.7972973  0.94594595 0.90540541 0.89189189\n",
      " 0.81081081 0.85135135 1.         0.87837838]\n",
      "Tenure: [0.2 0.1 0.8 0.7 0.4 0.6 0.3 1.  0.5 0.9 0. ]\n",
      "Balance: [0.         0.33403148 0.63635718 ... 0.22865702 0.29922631 0.51870777]\n",
      "NumOfProducts: [0.         0.66666667 0.33333333 1.        ]\n",
      "HasCrCard: [1 0]\n",
      "IsActiveMember: [1 0]\n",
      "EstimatedSalary: [0.50673489 0.56270874 0.56965435 ... 0.21039009 0.46442905 0.19091423]\n",
      "Exited: [1 0]\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(f'{col}: {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train set(80% Data) and test set(20% Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited',axis='columns')\n",
    "y = df['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>0.498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.871009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.489140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.335260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>0.548</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0.482</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.497643</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.252395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>0.456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.587837</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.629710</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.730219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.205353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.298</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "7378        0.498       0  0.216216     0.8  0.000000       0.333333   \n",
       "2489        0.728       0  0.135135     0.6  0.489140       0.000000   \n",
       "3843        0.866       0  0.270270     0.1  0.000000       0.666667   \n",
       "4560        0.548       1  0.243243     0.0  0.000000       0.333333   \n",
       "1309        0.482       0  0.162162     0.8  0.497643       0.333333   \n",
       "9752        0.680       0  0.040541     0.8  0.000000       0.333333   \n",
       "1963        0.456       0  0.216216     0.8  0.587837       0.333333   \n",
       "815         0.790       0  0.094595     0.5  0.629710       0.333333   \n",
       "2644        0.772       0  0.121622     0.5  0.205353       0.000000   \n",
       "729         0.298       1  0.527027     0.1  0.000000       0.000000   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "7378          1               1         0.871009  \n",
       "2489          1               1         0.335260  \n",
       "3843          1               1         0.400873  \n",
       "4560          1               0         0.558025  \n",
       "1309          0               0         0.252395  \n",
       "9752          1               1         0.778931  \n",
       "1963          1               0         0.333378  \n",
       "815           1               0         0.730219  \n",
       "2644          0               1         0.960693  \n",
       "729           0               0         0.656867  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Deep Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix , classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Activation in the output layer and binary crossentropy loss is used because output is in the form of 1 or 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACHAL SHAH\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\ACHAL SHAH\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.5096 - acc: 0.7962\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.4910 - acc: 0.7962\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4758 - acc: 0.7962\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4635 - acc: 0.7962\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4546 - acc: 0.7962\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4481 - acc: 0.7962\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.4426 - acc: 0.7962\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.4383 - acc: 0.8001\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4353 - acc: 0.8130\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4327 - acc: 0.8163\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4306 - acc: 0.8196\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4284 - acc: 0.8215\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4276 - acc: 0.8227\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4256 - acc: 0.8241\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4249 - acc: 0.8260\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4233 - acc: 0.8279\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4222 - acc: 0.8282\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 44us/sample - loss: 0.4208 - acc: 0.8275\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4203 - acc: 0.8291\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.4194 - acc: 0.8304\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.4184 - acc: 0.8294\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4176 - acc: 0.8311\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4166 - acc: 0.8295\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4165 - acc: 0.8304\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.4155 - acc: 0.8319\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4141 - acc: 0.8322\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4136 - acc: 0.8320\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4130 - acc: 0.8329\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.4123 - acc: 0.8317\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4105 - acc: 0.8339\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.4080 - acc: 0.8349\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4056 - acc: 0.8369\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4024 - acc: 0.8389\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3999 - acc: 0.8388\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3954 - acc: 0.8413\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3886 - acc: 0.845 - 0s 42us/sample - loss: 0.3909 - acc: 0.8446\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3868 - acc: 0.8441\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3828 - acc: 0.8478\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3789 - acc: 0.8493\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3763 - acc: 0.8499\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3715 - acc: 0.8514\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3676 - acc: 0.8546\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3644 - acc: 0.8528\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3626 - acc: 0.8530\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3621 - acc: 0.8530\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3618 - acc: 0.8537\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3608 - acc: 0.8543\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3596 - acc: 0.8534\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3594 - acc: 0.8543\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3584 - acc: 0.8534\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3577 - acc: 0.8549\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3574 - acc: 0.8547\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 46us/sample - loss: 0.3566 - acc: 0.8545\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3568 - acc: 0.8554\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3568 - acc: 0.8559\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3552 - acc: 0.8553\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3564 - acc: 0.8541\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3555 - acc: 0.8553\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.3550 - acc: 0.8549\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3553 - acc: 0.8546\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3553 - acc: 0.8547\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3545 - acc: 0.8543\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3544 - acc: 0.8553\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 45us/sample - loss: 0.3542 - acc: 0.8550\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 52us/sample - loss: 0.3543 - acc: 0.8555\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3549 - acc: 0.8547\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 0s 36us/sample - loss: 0.3540 - acc: 0.8554\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3531 - acc: 0.8562\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3540 - acc: 0.8558\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 38us/sample - loss: 0.3540 - acc: 0.8554\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 48us/sample - loss: 0.3540 - acc: 0.8559\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 56us/sample - loss: 0.3528 - acc: 0.8556\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3538 - acc: 0.8565\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 50us/sample - loss: 0.3536 - acc: 0.8551\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 53us/sample - loss: 0.3542 - acc: 0.8549\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 49us/sample - loss: 0.3533 - acc: 0.8550\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3531 - acc: 0.8543\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3529 - acc: 0.8555\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 42us/sample - loss: 0.3524 - acc: 0.8551\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3527 - acc: 0.8544\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3527 - acc: 0.8564\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3530 - acc: 0.8549\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 0s 34us/sample - loss: 0.3522 - acc: 0.8566\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3531 - acc: 0.8562\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3528 - acc: 0.8551\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3526 - acc: 0.8562\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3529 - acc: 0.8547\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3522 - acc: 0.8560\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3520 - acc: 0.8547\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3529 - acc: 0.8539\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3519 - acc: 0.8572\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3533 - acc: 0.8543\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 39us/sample - loss: 0.3517 - acc: 0.8543\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3522 - acc: 0.8543\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 33us/sample - loss: 0.3524 - acc: 0.8549\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 40us/sample - loss: 0.3521 - acc: 0.8546\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 35us/sample - loss: 0.3515 - acc: 0.8554\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3522 - acc: 0.8536\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 32us/sample - loss: 0.3515 - acc: 0.8551\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 37us/sample - loss: 0.3515 - acc: 0.8554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a7e279fc8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(7, input_shape=(9,), activation='relu'),\n",
    "    keras.layers.Dense(5, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 37us/sample - loss: 0.3416 - acc: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3415518038272858, 0.86]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15691918],\n",
       "       [0.0885756 ],\n",
       "       [0.28062415],\n",
       "       [0.04174185],\n",
       "       [0.02688918]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = model.predict(X_test)\n",
    "yp[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covert 2 dimensional array into one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2239    1\n",
       "1502    0\n",
       "2221    1\n",
       "6593    0\n",
       "9666    0\n",
       "4843    0\n",
       "2266    1\n",
       "3580    0\n",
       "9763    0\n",
       "3130    1\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      1593\n",
      "           1       0.80      0.42      0.55       407\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.83      0.70      0.73      2000\n",
      "weighted avg       0.85      0.86      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that recall and f1-score for output 1 is not very efficient. This is because there were only 2037 'Exited=1' samples vs 7963 'Exited=0' samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE - Synthetic Minority Oversampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It generates synthetic over samples of minority class using K nearest neighbour algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited',axis='columns')\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As of now for imblearn to work, do the following in command prompt: -\n",
    "pip install scikit-learn==0.23.1\n",
    "\n",
    "pip install imbalanced-learn==0.7.0\n",
    "\n",
    "Restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic minority class samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_sample(X, y)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train set(80% Data) and test set(20% Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=5, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6370\n",
       "0    6370\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes in training Data\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Added Dropout Regularization layers to avoid overfitting. It randomly misses nodes. 20% here in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12740/12740 [==============================] - 1s 56us/sample - loss: 0.6799 - acc: 0.5767\n",
      "Epoch 2/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.6598 - acc: 0.6214\n",
      "Epoch 3/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.6423 - acc: 0.6338\n",
      "Epoch 4/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.6216 - acc: 0.6637\n",
      "Epoch 5/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.6022 - acc: 0.6903\n",
      "Epoch 6/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5873 - acc: 0.7007\n",
      "Epoch 7/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5772 - acc: 0.7053\n",
      "Epoch 8/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5725 - acc: 0.7068\n",
      "Epoch 9/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.5625 - acc: 0.7104\n",
      "Epoch 10/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5616 - acc: 0.7107\n",
      "Epoch 11/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.5543 - acc: 0.7216\n",
      "Epoch 12/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5493 - acc: 0.7196\n",
      "Epoch 13/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.5456 - acc: 0.7245\n",
      "Epoch 14/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.5454 - acc: 0.7192\n",
      "Epoch 15/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5455 - acc: 0.7188\n",
      "Epoch 16/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5398 - acc: 0.7271\n",
      "Epoch 17/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.5415 - acc: 0.7230\n",
      "Epoch 18/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5371 - acc: 0.7279\n",
      "Epoch 19/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5384 - acc: 0.7226\n",
      "Epoch 20/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.5346 - acc: 0.7317\n",
      "Epoch 21/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5377 - acc: 0.7254\n",
      "Epoch 22/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.5370 - acc: 0.7248\n",
      "Epoch 23/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5335 - acc: 0.7240\n",
      "Epoch 24/100\n",
      "12740/12740 [==============================] - 0s 35us/sample - loss: 0.5316 - acc: 0.7341\n",
      "Epoch 25/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5299 - acc: 0.7323\n",
      "Epoch 26/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5325 - acc: 0.7323\n",
      "Epoch 27/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.5342 - acc: 0.7297\n",
      "Epoch 28/100\n",
      "12740/12740 [==============================] - 1s 43us/sample - loss: 0.5375 - acc: 0.7255\n",
      "Epoch 29/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.5336 - acc: 0.7290\n",
      "Epoch 30/100\n",
      "12740/12740 [==============================] - 1s 43us/sample - loss: 0.5367 - acc: 0.7276\n",
      "Epoch 31/100\n",
      "12740/12740 [==============================] - 1s 41us/sample - loss: 0.5346 - acc: 0.7295\n",
      "Epoch 32/100\n",
      "12740/12740 [==============================] - 1s 39us/sample - loss: 0.5354 - acc: 0.7285\n",
      "Epoch 33/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.5367 - acc: 0.7319\n",
      "Epoch 34/100\n",
      "12740/12740 [==============================] - 1s 42us/sample - loss: 0.5333 - acc: 0.7312\n",
      "Epoch 35/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.5303 - acc: 0.7315\n",
      "Epoch 36/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5332 - acc: 0.7282\n",
      "Epoch 37/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5361 - acc: 0.7305\n",
      "Epoch 38/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5312 - acc: 0.7321\n",
      "Epoch 39/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5359 - acc: 0.7298\n",
      "Epoch 40/100\n",
      "12740/12740 [==============================] - 1s 44us/sample - loss: 0.5347 - acc: 0.7294\n",
      "Epoch 41/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5312 - acc: 0.7319\n",
      "Epoch 42/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5318 - acc: 0.7342\n",
      "Epoch 43/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5352 - acc: 0.7297\n",
      "Epoch 44/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5356 - acc: 0.7308\n",
      "Epoch 45/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5357 - acc: 0.7262\n",
      "Epoch 46/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5361 - acc: 0.7291\n",
      "Epoch 47/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5327 - acc: 0.7306\n",
      "Epoch 48/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5261 - acc: 0.7376\n",
      "Epoch 49/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5283 - acc: 0.7314\n",
      "Epoch 50/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5364 - acc: 0.7216\n",
      "Epoch 51/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5313 - acc: 0.7311\n",
      "Epoch 52/100\n",
      "12740/12740 [==============================] - 1s 47us/sample - loss: 0.5324 - acc: 0.7304\n",
      "Epoch 53/100\n",
      "12740/12740 [==============================] - 1s 48us/sample - loss: 0.5301 - acc: 0.7307\n",
      "Epoch 54/100\n",
      "12740/12740 [==============================] - 1s 42us/sample - loss: 0.5281 - acc: 0.7354\n",
      "Epoch 55/100\n",
      "12740/12740 [==============================] - 1s 50us/sample - loss: 0.5358 - acc: 0.7279\n",
      "Epoch 56/100\n",
      "12740/12740 [==============================] - 1s 46us/sample - loss: 0.5295 - acc: 0.7305\n",
      "Epoch 57/100\n",
      "12740/12740 [==============================] - 1s 39us/sample - loss: 0.5302 - acc: 0.7334\n",
      "Epoch 58/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5326 - acc: 0.7319\n",
      "Epoch 59/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.5261 - acc: 0.7319\n",
      "Epoch 60/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5311 - acc: 0.7284\n",
      "Epoch 61/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5256 - acc: 0.7336\n",
      "Epoch 62/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5319 - acc: 0.7291\n",
      "Epoch 63/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5294 - acc: 0.7298\n",
      "Epoch 64/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5326 - acc: 0.7317\n",
      "Epoch 65/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5288 - acc: 0.73450s - loss: 0.5341 - acc\n",
      "Epoch 66/100\n",
      "12740/12740 [==============================] - 1s 45us/sample - loss: 0.5315 - acc: 0.7324\n",
      "Epoch 67/100\n",
      "12740/12740 [==============================] - 1s 42us/sample - loss: 0.5262 - acc: 0.7304\n",
      "Epoch 68/100\n",
      "12740/12740 [==============================] - 1s 47us/sample - loss: 0.5274 - acc: 0.7389\n",
      "Epoch 69/100\n",
      "12740/12740 [==============================] - 1s 44us/sample - loss: 0.5286 - acc: 0.7305\n",
      "Epoch 70/100\n",
      "12740/12740 [==============================] - 1s 44us/sample - loss: 0.5301 - acc: 0.7307\n",
      "Epoch 71/100\n",
      "12740/12740 [==============================] - 1s 46us/sample - loss: 0.5301 - acc: 0.7330\n",
      "Epoch 72/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5286 - acc: 0.7356\n",
      "Epoch 73/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5292 - acc: 0.7345\n",
      "Epoch 74/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5282 - acc: 0.7312\n",
      "Epoch 75/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5284 - acc: 0.7317\n",
      "Epoch 76/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5274 - acc: 0.7317\n",
      "Epoch 77/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5321 - acc: 0.7311\n",
      "Epoch 78/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5297 - acc: 0.7334\n",
      "Epoch 79/100\n",
      "12740/12740 [==============================] - 1s 43us/sample - loss: 0.5288 - acc: 0.7297\n",
      "Epoch 80/100\n",
      "12740/12740 [==============================] - 1s 45us/sample - loss: 0.5291 - acc: 0.7290\n",
      "Epoch 81/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5252 - acc: 0.7332\n",
      "Epoch 82/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5268 - acc: 0.7239\n",
      "Epoch 83/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5278 - acc: 0.7286\n",
      "Epoch 84/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.5296 - acc: 0.7258\n",
      "Epoch 85/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5250 - acc: 0.7349\n",
      "Epoch 86/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5322 - acc: 0.7316\n",
      "Epoch 87/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.5288 - acc: 0.7297\n",
      "Epoch 88/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5265 - acc: 0.7315\n",
      "Epoch 89/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5244 - acc: 0.7363\n",
      "Epoch 90/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5279 - acc: 0.7358\n",
      "Epoch 91/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5275 - acc: 0.7329\n",
      "Epoch 92/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5270 - acc: 0.7363\n",
      "Epoch 93/100\n",
      "12740/12740 [==============================] - 0s 39us/sample - loss: 0.5258 - acc: 0.7374\n",
      "Epoch 94/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5295 - acc: 0.7330\n",
      "Epoch 95/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5289 - acc: 0.7279\n",
      "Epoch 96/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5264 - acc: 0.7364\n",
      "Epoch 97/100\n",
      "12740/12740 [==============================] - 1s 40us/sample - loss: 0.5327 - acc: 0.7319\n",
      "Epoch 98/100\n",
      "12740/12740 [==============================] - 0s 36us/sample - loss: 0.5274 - acc: 0.7301\n",
      "Epoch 99/100\n",
      "12740/12740 [==============================] - 0s 37us/sample - loss: 0.5255 - acc: 0.7283\n",
      "Epoch 100/100\n",
      "12740/12740 [==============================] - 0s 38us/sample - loss: 0.5266 - acc: 0.7281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a7fd4e648>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(7, input_shape=(9,), activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(5, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3186/3186 [==============================] - 0s 83us/sample - loss: 0.4897 - acc: 0.7677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4897465152667142, 0.7677338]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25089496],\n",
       "       [0.9410362 ],\n",
       "       [0.5757518 ],\n",
       "       [0.8829934 ],\n",
       "       [0.32264483]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = model.predict(X_test)\n",
    "yp[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covert 2 dimensional array into one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 0, 1, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095     1\n",
       "8363     1\n",
       "13789    1\n",
       "1676     1\n",
       "10533    1\n",
       "898      1\n",
       "11747    1\n",
       "4141     0\n",
       "12854    1\n",
       "6453     0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78      1593\n",
      "           1       0.80      0.72      0.76      1593\n",
      "\n",
      "    accuracy                           0.77      3186\n",
      "   macro avg       0.77      0.77      0.77      3186\n",
      "weighted avg       0.77      0.77      0.77      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Overall Efficiency of Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
